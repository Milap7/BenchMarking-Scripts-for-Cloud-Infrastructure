#Project:

Benchmarking of CPU, Memory, Disk and Network. Programming in C to benchmark various parts of the computer system and comparing the results with various benchmarking tools( HPL, PMBW etc).

##Getting Started:

These instructions are important and need to executed to deploy the code on the cluster and see the results.

##Prerequisites:

Linux environment. Access to the virtual cluster found at 129.114.33.105 for the formal testing and evaluation.  
If evaluating on local machine, then C compiler is required (gcc).                        


##Running the benchmarking programs:

There are four benchmarks : CPU, Memory, Disk and Network.
###To run CPU Benchmark: 
The CPU Benchmark runs 1 trillion arithmetic operations and measures the time taken by the processor and converts in Giga Operations ( Giga operations / sec). The operations are done over 4 types of primitive atomic data types ( char, short, int, long), each called as Quarter Precision, Half Precision, Single Precision and Double Precision respectively. The concurrency is 1,2 and 4 threads.


Step 1: To compile the code :
cd cs553-pa1/cpu
gcc -o CPUFIN MyCPUKBench.c -lpthread  


Step 2: To execute all the precision operations and generate results for each of them into an .out files (9 files) :
        make run
This function submits jobs and scheduler manages it on the cluster. It executes all  .slurm 
Files. The slurm files are the batch files that executes the C program and also gives the input from  .dat files for each type of operations and concurrency and exports the result into .out
Files into a output folder.
For example : 
sbatch cpu_QP_2.slurm
The structure of the slurm file :
#!/bin/bash
#SBATCH --nodes=01
#SBATCH --output=output/cpu_QP_2thread.out


echo $SLURM_JOB_NODELIST


./CPUFIN cpu_QP_2thread.dat


Step 3: Command to check if the jobs have been completed: 
        squeue
The job with unique job ID and username can be seen, if completed it will be removed the list.
To check the output.
Step 4: 
cd ~/output
        cat *.out 
This displays all the output in the format specified in the C program.
Example:
Workload Concurrencey MyCPUBenchValue TheroticalValue Efficiencey
   QP                4               7.194356                 73.599998     9.774864


Where CPUFIN is the C program instance generated by the gcc and cpu_QP_2thread.dat is the input file required the program.


The HPL Benchmark tool also runs in the same way:
Step 1:
 cd ~/LinPack_Slurm
Step 2:
 sbatch LinPack_1t.slurm
         sbatch LinPack_2t.slurm
 sbatch LinPack_4t.slurm


Step 3: Command to check if the jobs have been completed: 
        squeue
The job with unique job ID and username can be seen, if completed it will be removed the list.
To check the output
Step 4: 
        cat *.out 
This displays all the output in the format specified in the HPL program.






###To run Memory Benchmark: 
The Memory Benchmark operates 100 times over 1 GB of data. This data is reserved in the DRAM (Dynamic Memory), then copied and pasted into another locations allocated dynamically ( Read + Write Operation). There is two type of operations, Read/Write Sequentially and Read/Write Randomly. The concurrency is 1,2 and 4 threads.
        
Step 1: To compile the code :
cd cs553-pa1/memory
gcc -o MEMFIN MyRAMBench.c -lpthread
Step 2: To execute all types of Read/Write (Sequential and Random)  operations with concurrency and generate results for each of them into.out files (18  files):
        make run
The command works the same way as  mentioned in CPU benchmarking.
The Read/Write operations are done using memcpy() functions, with three types of block size( size of data to be transferred in each iterations), 1KB, 1 MB and 10 MB. The result is measure in throughput, that is amount of GigaBytes transferred per second.
This also executes the file which calculates latency in terms of microseconds, latency is the time it takes the cpu to access the RAM. 
Example of slurm files :
        sbatch RWR_1_2t.slurm
        
        #!/bin/bash
#SBATCH --nodes=01
#SBATCH --output=output/memory-RWR-1-1thread.out


echo $SLURM_JOB_NODELIST


./RAMFIN memory_RWR_1_2thread.dat




Step 3: Command to check if the jobs have been completed: 
        squeue
The job with unique job ID and username can be seen, if completed it will be removed the list.
To check the output
Step 4: 
cd ~/output
        cat *.out 
This displays all the output in the format specified in the C program.
Example:


Workload Concurrency BlockSize MyRAMBench TheorValue    MyRAMBenchEff
 RWS               4              1000000        6.974     34.080002     20.464518


The PMBW Benchmark tool also runs in the same way:
Step 1:
 cd ~/pmbw-0.6.2
Step 2:
 sbatch pmbw1.slurm
         sbatch pmbw2.slurm
 sbatch pmbw4.slurm


Step 3: Command to check if the jobs have been completed: 
        squeue
The job with unique job ID and username can be seen, if completed it will be removed the list.
To check the output
Step 4: 
        cd output
        cat *.out 
This displays all the output in the format specified in the PMBW program.




###To run Disk Benchmark:
The Disk Benchmark operates 10 GB of data. A file of size 10 GB is created and stored on the disk. The Read operation is performed over this file. The operations is of Sequential Read or Random Read. The Write operation is performed by creating a file of size of 10 GB and measuring the throughput obtained ( MB/sec), again it can Sequential Write or Random Write. The concurrency is 1,2 and 4 threads.
        
Step 1: To compile the code :
cd cs553-pa1/disk
gcc -o DISKFIN MyDISKBench.c -lpthread  


Step 2: To execute all types of Read/Write (Sequential and Random)  operations with concurrency and generate results for each of them into.out files (32  files):
        make run
The command works the same way as  mentioned in CPU benchmarking.
The Read/Write operations are done using fgets() and fputs() functions, with three types of block size( size of data to be transferred in each iterations), 1MB, 10 MB and 100 MB. The result is measure in throughput, that is amount of MegaBytes transferred per second.
This also executes the file which calculates latency in terms of microseconds and IOPS (In/Out Operations Per Second), latency is the time it takes the cpu to access the Disk. 
Example of slurm files :
        
sbatch RS_1000_1t.slurm
        #!/bin/bash
#SBATCH --nodes=01
#SBATCH --output=output/disk-RS-1000-1thread.out


echo $SLURM_JOB_NODELIST


./DISKFIN disk_RS_1000_1thread.dat


Step 3: Command to check if the jobs have been completed: 
        squeue
The job with unique job ID and username can be seen, if completed it will be removed the list.
To check the output.
Step 4: 
cd ~/output
        cat *.out 
This displays all the output in the format specified in the C program.
Example:


WorkLoad Concurrency BlockSize MyDiskThroughput TheorThroug Efficiency
RS         4         1000000    150.516373      600.000000 25.086063


The IOZone Benchmark tool also runs in the same way:
Step 1:
Download the iozone binary executable file. 
Step 2:
 ./iozone -i 0 -i 1 -i 2 -s 1073741 -r 1024 -t 4 -Q
//-i 0 is read operation, -i 1 is write operation, -i 2 is random read/write operation, -s defines the size of file, -r defines the block size, -t defines the number of threads.
This command displays the output in the terminal.




###To run Network Benchmark:
The Network Benchmark operates 100 times over 1 GB of data. The data is transferred over the network from the client to the server using TCP (Transmission Control Protocol) and UDP (User Datagram Protocol). The data is transferred using block size of 1KB and 32KB. The concurrency is 1,2,4 and 8 threads.


Step 1: To compile the code :
cd cs553-pa1/network
gcc -o NETFIN MyNETBench_1.c -lpthread  


Step 2: To execute all types of Read/Write (Sequential and Random)  operations with concurrency and generate results for each of them into.out files (16  files):
        srun ./NETFIN network-TCP-1000-4thread.dat Server
        // Setup Server on one node
        srun./NETFIN network-TCP-1000-4thread.dat Client
        // Setup Client on another node


Using the srun command, two different blue(or any other) compute nodes are set up for server and client each. Then the readings were recorded, thus there are no .out files.
The Read/Write operations are done using send() and read() functions, with three types of block size( size of data to be transferred in each iterations), 1KB and 32 KB over the socket created by the server to which the client connects using IP address and port number. The result is measure in throughput, that is amount of MegaBytes transferred per second. The latency (ping - pong 1 byte of data), in terms of time per RTT (round - trip - time) is calculated in ms, milliseconds over 1. million operations 


On successful completion the output is displayed in following manner:
Step 3: 
Protocol Concurrency BlockSize MyNETThroughput TheorThroug Efficiency
TCP         1         1000     233.96                    10000.00    2.3396                                        
The Iperf Benchmark tool also runs in the same way:
Step 1:
Download the iperf version 3 binary executable file from https://iperf.fr/iperf-download.php
Step 2:
./iperf3 -s //Server Setup on 1 compute node
./iperf -c 192.168.0.48 -w 1000 -P 1 
// Client setup with local IP address of the client, -w specifies the block size (1 KB or 32 KB), -P specifies no of threads.




**MyNETBench_2.c is code for UDP
** The codes have a lot of warnings, please ignore them












To check the output




Step 3:
Server Output:
   Client Output